{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac67275",
   "metadata": {},
   "source": [
    "## Fixed Obstacle and fixed target position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48cb5fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.0 (SDL 2.0.16, Python 3.9.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import pygame\n",
    "import numpy as np\n",
    "import cv2\n",
    "class AgentEnv(gym.Env):\n",
    "    def __init__(self):        \n",
    "        pygame.init()\n",
    "        pygame.font.init()\n",
    "        self.width = 800\n",
    "        self.height = 600\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.fps = 15   # frame per second\n",
    "        # Create a VideoWriter object to save the video\n",
    "        self.fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        self.out = cv2.VideoWriter('fixed_obstacle_and_target.mp4', self.fourcc, self.fps, (self.width, self.height))\n",
    "        \n",
    "        self.grid_size = 40\n",
    "        self.grid_width = self.width//self.grid_size ## no. of grids in row\n",
    "        self.grid_height = self.height//self.grid_size  ## no. of grids in column\n",
    "        \n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        ## self.observation_space = gym.spaces.Tuple((gym.spaces.Discrete(self.grid_width),gym.spaces.Discrete(self.grid_height)))\n",
    "        self.observation_space = gym.spaces.Box(np.array([0,0]),np.array([self.grid_width-1,self.grid_height-1]))\n",
    "        \n",
    "        self.agent_image = pygame.image.load('Documents\\TANK.png')\n",
    "        self.agent_image = pygame.transform.scale(self.agent_image,(self.grid_size ,self.grid_size))\n",
    "        self.player_image = pygame.transform.rotate(self.agent_image, 180)\n",
    "        self.player_pos = [0, 0]\n",
    "        self.target_pos = [self.grid_width - 1, self.grid_height - 1]\n",
    "        self.target_image = pygame.Rect(self.target_pos[0]*self.grid_size,self.target_pos[1]*self.grid_size,self.grid_size,self.grid_size)\n",
    "        \n",
    "        self.obstacle1_pos = [self.grid_width - 7, self.grid_height - 9]\n",
    "        self.obstacle1_image = pygame.Rect(self.obstacle1_pos[0]*self.grid_size,self.obstacle1_pos[1]*self.grid_size,self.grid_size,self.grid_size)\n",
    "\n",
    "    def step(self,action):\n",
    "        \n",
    "        if action == 0:  # up\n",
    "            self.player_pos[1] = max(0, self.player_pos[1] - 1)\n",
    "            reward = -np.sqrt((self.player_pos[0]-self.target_pos[0])**2 + (self.player_pos[1]-self.target_pos[1])**2)\n",
    "        elif action == 1:  # down\n",
    "            self.player_pos[1] = min(self.grid_height - 1, self.player_pos[1] + 1)\n",
    "            reward = -np.sqrt((self.player_pos[0]-self.target_pos[0])**2 + (self.player_pos[1]-self.target_pos[1])**2)\n",
    "        elif action == 2:  # left\n",
    "            self.player_pos[0] = max(0, self.player_pos[0] - 1)\n",
    "            reward = -np.sqrt((self.player_pos[0]-self.target_pos[0])**2 + (self.player_pos[1]-self.target_pos[1])**2)\n",
    "        elif action == 3:  # right\n",
    "            self.player_pos[0] = min(self.grid_width - 1, self.player_pos[0] + 1)\n",
    "            reward = -np.sqrt((self.player_pos[0]-self.target_pos[0])**2 + (self.player_pos[1]-self.target_pos[1])**2)\n",
    "        \n",
    "        if self.player_pos == self.target_pos:\n",
    "            reward += 2000\n",
    "            done = True\n",
    "        elif self.player_pos == self.obstacle1_pos or self.player_pos == self.obstacle1_pos + [1,0] or self.player_pos == self.obstacle1_pos + [0,1] or self.player_pos == self.obstacle1_pos +[1,1]:\n",
    "            reward -= 1000\n",
    "            done = True\n",
    "\n",
    "    \n",
    "        else:\n",
    "            reward -= 1\n",
    "            done = False\n",
    "        return self.player_pos, reward, done, {}\n",
    "    \n",
    "    def reset(self):\n",
    "        self.player_pos = [0, 0]\n",
    "        return self.player_pos\n",
    "\n",
    "    def render(self,score,i,num_episodes,mode = \"rgb_array\"):\n",
    "        self.screen.fill((255, 255, 255))\n",
    "        self.screen.blit(self.player_image, (self.player_pos[0] * self.grid_size, self.player_pos[1] * self.grid_size))\n",
    "        pygame.draw.rect(self.screen,(0,255,0),self.target_image)\n",
    "        pygame.draw.rect(self.screen,(255,0,0),self.obstacle1_image)\n",
    "        font = pygame.font.Font(None, 36)\n",
    "        score_text = font.render(f'Score: {score}', True, (0, 0, 255))\n",
    "        self.screen.blit(score_text, (600, 20))\n",
    "        \n",
    "        # Save the frame as a PNG image\n",
    "        pygame.image.save(self.screen, 'frame.png')\n",
    "    \n",
    "        # Add the frame to the video\n",
    "        self.frame = cv2.imread('frame.png')\n",
    "        self.out.write(self.frame)\n",
    "        \n",
    "        pygame.display.update()\n",
    "        self.clock.tick(self.fps)\n",
    "        if i==num_episodes-1:\n",
    "            self.out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116bfe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\gym\\spaces\\box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Score: 1512.1256042964453\n",
      "Score: 1505.4965361771674\n",
      "Score: 1466.1091481660133\n",
      "Score: 1588.8615567518605\n",
      "Score: 1560.060688774664\n",
      "Score: 1512.05120368788\n",
      "Score: 1532.8764925338244\n",
      "Score: 1455.993730196706\n",
      "Score: 1589.081491136875\n",
      "Score: 1449.362357168195\n",
      "Avg Score = 1517.201880888963\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = AgentEnv()   # Create the environment\n",
    "# model = PPO('MlpPolicy', env, verbose=1)  # Create the PPO agent\n",
    "# model.learn(total_timesteps=100000)    # Train the agent for 100000 timesteps\n",
    "# model.save('Documents\\Trained Model_2D\\Agent_Target_Obstacle_100000_timesteps')\n",
    "model = PPO.load('Documents\\Trained Model_2D\\Agent_Target_Obstacle_100000_timesteps.zip', env = env)\n",
    "\n",
    "                  \n",
    "obs = env.reset()\n",
    "score_tot = 0\n",
    "num_episodes = 10\n",
    "for i in range(num_episodes):\n",
    "    score = 0\n",
    "    while True:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, done,info = env.step(action)       \n",
    "        score += rewards\n",
    "        env.render(score,i,num_episodes)\n",
    "        if done == True:\n",
    "            break\n",
    "    print('Score: ' + str(score))\n",
    "    obs = env.reset()\n",
    "    score_tot += score\n",
    "print('Avg Score = ' + str(score_tot/num_episodes))\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26049f8f",
   "metadata": {},
   "source": [
    "## Changing Obstacle position after training the agent at different position of obstacle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b431bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import pygame\n",
    "import numpy as np\n",
    "import cv2\n",
    "class AgentEnv(gym.Env):\n",
    "    def __init__(self):        \n",
    "        pygame.init()\n",
    "        pygame.font.init()\n",
    "        self.width = 800\n",
    "        self.height = 600\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.fps = 15   # frame per second\n",
    "        # Create a VideoWriter object to save the video\n",
    "        self.fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        self.out = cv2.VideoWriter('Changing_obstacle_after_training_agent.mp4', self.fourcc, self.fps, (self.width, self.height))\n",
    "        \n",
    "        \n",
    "        self.grid_size = 40\n",
    "        self.grid_width = self.width//self.grid_size ## no. of grids in row\n",
    "        self.grid_height = self.height//self.grid_size  ## no. of grids in column\n",
    "        \n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        ## self.observation_space = gym.spaces.Tuple((gym.spaces.Discrete(self.grid_width),gym.spaces.Discrete(self.grid_height)))\n",
    "        self.observation_space = gym.spaces.Box(np.array([0,0,0,0]),np.array([self.grid_width-1,self.grid_height-1,self.grid_width-1,self.grid_height-1]))\n",
    "        \n",
    "        self.agent_image = pygame.image.load('Documents\\TANK.png')\n",
    "        self.agent_image = pygame.transform.scale(self.agent_image,(self.grid_size ,self.grid_size))\n",
    "        self.player_image = pygame.transform.rotate(self.agent_image, 180)\n",
    "        self.player_pos = [0, 0]\n",
    "        self.target_pos = [self.grid_width - 1, self.grid_height - 1]\n",
    "        self.target_image = pygame.Rect(self.target_pos[0]*self.grid_size,self.target_pos[1]*self.grid_size,self.grid_size,self.grid_size)\n",
    "        \n",
    "        self.obstacle1_pos = [self.grid_width - 4, self.grid_height - 1]\n",
    "        self.obstacle1_image = pygame.Rect(self.obstacle1_pos[0]*self.grid_size,self.obstacle1_pos[1]*self.grid_size,self.grid_size,self.grid_size)\n",
    "\n",
    "    def step(self,action):\n",
    "        reward = 0\n",
    "        if action == 0:  # up\n",
    "            self.player_pos[1] = max(0, self.player_pos[1] - 1)\n",
    "            reward = -np.sqrt((self.player_pos[0]-self.target_pos[0])**2 + (self.player_pos[1]-self.target_pos[1])**2)*10\n",
    "            reward -= 23 -np.sqrt((self.player_pos[0]-self.obstacle1_pos[0])**2 + (self.player_pos[1]-self.obstacle1_pos[1])**2)\n",
    "        elif action == 1:  # down\n",
    "            self.player_pos[1] = min(self.grid_height - 1, self.player_pos[1] + 1)\n",
    "            reward = -np.sqrt((self.player_pos[0]-self.target_pos[0])**2 + (self.player_pos[1]-self.target_pos[1])**2)*10\n",
    "            reward -= 23 -np.sqrt((self.player_pos[0]-self.obstacle1_pos[0])**2 + (self.player_pos[1]-self.obstacle1_pos[1])**2)\n",
    "        elif action == 2:  # left\n",
    "            self.player_pos[0] = max(0, self.player_pos[0] - 1)\n",
    "            reward = -np.sqrt((self.player_pos[0]-self.target_pos[0])**2 + (self.player_pos[1]-self.target_pos[1])**2)*10\n",
    "            reward -= 23 -np.sqrt((self.player_pos[0]-self.obstacle1_pos[0])**2 + (self.player_pos[1]-self.obstacle1_pos[1])**2)\n",
    "        elif action == 3:  # right\n",
    "            self.player_pos[0] = min(self.grid_width - 1, self.player_pos[0] + 1)\n",
    "            reward = -np.sqrt((self.player_pos[0]-self.target_pos[0])**2 + (self.player_pos[1]-self.target_pos[1])**2)*10\n",
    "            reward -= 23 -np.sqrt((self.player_pos[0]-self.obstacle1_pos[0])**2 + (self.player_pos[1]-self.obstacle1_pos[1])**2)\n",
    "        \n",
    "        if self.player_pos == self.target_pos:\n",
    "            reward += 2000\n",
    "            done = True\n",
    "        elif self.player_pos == self.obstacle1_pos:\n",
    "            reward -= 1000\n",
    "            done = True\n",
    "\n",
    "    \n",
    "        else:\n",
    "            reward -= 1\n",
    "            done = False\n",
    "        state1 = np.array([self.player_pos[0],self.player_pos[1],self.obstacle1_pos[0],self.obstacle1_pos[1]])\n",
    "        return state1, reward, done, {}\n",
    "    \n",
    "    def reset(self):\n",
    "        self.player_pos = [0, 0]\n",
    "        state1 = np.array([self.player_pos[0],self.player_pos[1],self.obstacle1_pos[0],self.obstacle1_pos[1]])\n",
    "        return state1\n",
    "\n",
    "    def render(self,score,i,num_episodes,mode = \"rgb_array\"):\n",
    "        self.screen.fill((255, 255, 255))\n",
    "        self.screen.blit(self.player_image, (self.player_pos[0] * self.grid_size, self.player_pos[1] * self.grid_size))\n",
    "        pygame.draw.rect(self.screen,(0,255,0),self.target_image)\n",
    "        pygame.draw.rect(self.screen,(255,0,0),self.obstacle1_image)\n",
    "        font = pygame.font.Font(None, 36)\n",
    "        score_text = font.render(f'Score: {score}', True, (0, 0, 255))\n",
    "        self.screen.blit(score_text, (600, 20))\n",
    "        # Save the frame as a PNG image\n",
    "        pygame.image.save(self.screen, 'frame.png')\n",
    "    \n",
    "        # Add the frame to the video\n",
    "        self.frame = cv2.imread('frame.png')\n",
    "        self.out.write(self.frame)\n",
    "        \n",
    "        pygame.display.update()\n",
    "        self.clock.tick(self.fps)\n",
    "        if i==num_episodes-1:\n",
    "             self.out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f17a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = AgentEnv()   # Create the environment\n",
    "model = PPO('MlpPolicy', env, verbose=1)  # Create the PPO agent\n",
    "model.learn(total_timesteps=100000)    # Train the agent for 10000 timesteps\n",
    "model.save('Documents\\Trained Model_2D\\Agent_Target_onlychange_Obstacle_100000_timesteps')\n",
    "# model = PPO.load('Documents\\Trained Model_2D\\Agent_Target_onlychange_Obstacle_100000_timesteps.zip', env = env)\n",
    "\n",
    "                  \n",
    "obs = env.reset()\n",
    "score_tot = 0\n",
    "num_episodes = 10\n",
    "for i in range(num_episodes):\n",
    "    score = 0\n",
    "    while True:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, done,info = env.step(action)       \n",
    "        score += rewards\n",
    "        env.render(score,i,num_episodes)\n",
    "        if done == True:\n",
    "            break\n",
    "    print('Score: ' + str(score))\n",
    "    obs = env.reset()\n",
    "    score_tot += score\n",
    "print('Avg Score = ' + str(score_tot/num_episodes))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581f3ac9",
   "metadata": {},
   "source": [
    "## Randomized Obstacle position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f57419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import pygame\n",
    "import numpy as np\n",
    "import cv2\n",
    "class AgentEnv(gym.Env):\n",
    "    def __init__(self):        \n",
    "        pygame.init()\n",
    "        pygame.font.init()\n",
    "        self.width = 800\n",
    "        self.height = 600\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.fps = 15   # frame per second\n",
    "        self.grid_size = 40\n",
    "        \n",
    "        # Create a VideoWriter object to save the video\n",
    "        self.fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        self.out = cv2.VideoWriter('randomized_obstacle_and_fixed_target.mp4', self.fourcc, self.fps, (self.width, self.height))\n",
    "        \n",
    "        self.grid_width = self.width//self.grid_size ## no. of grids in row\n",
    "        self.grid_height = self.height//self.grid_size  ## no. of grids in column\n",
    "        \n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        ## self.observation_space = gym.spaces.Tuple((gym.spaces.Discrete(self.grid_width),gym.spaces.Discrete(self.grid_height)))\n",
    "        self.observation_space = gym.spaces.Box(np.array([0,0,0,0]),np.array([self.grid_width-1,self.grid_height-1,self.grid_width-1,self.grid_height-1]))\n",
    "        \n",
    "        self.agent_image = pygame.image.load('Documents\\TANK.png')\n",
    "        self.agent_image = pygame.transform.scale(self.agent_image,(self.grid_size ,self.grid_size))\n",
    "        self.player_image = pygame.transform.rotate(self.agent_image, 180)\n",
    "        self.player_pos = [0, 0]\n",
    "        self.target_pos = [self.grid_width - 7, self.grid_height - 1]\n",
    "        self.target_image = pygame.Rect(self.target_pos[0]*self.grid_size,self.target_pos[1]*self.grid_size,self.grid_size,self.grid_size)\n",
    "        \n",
    "        self.obstacle1_pos = [self.grid_width - 7, self.grid_height - 9]\n",
    "        self.obstacle1_image = pygame.Rect(self.obstacle1_pos[0]*self.grid_size,self.obstacle1_pos[1]*self.grid_size,self.grid_size,self.grid_size)\n",
    "\n",
    "    def step(self,action):\n",
    "        \n",
    "        if action == 0:  # up\n",
    "            self.player_pos[1] = max(0, self.player_pos[1] - 1)\n",
    "            reward = -np.sqrt((self.player_pos[0]-self.target_pos[0])**2 + (self.player_pos[1]-self.target_pos[1])**2)\n",
    "        elif action == 1:  # down\n",
    "            self.player_pos[1] = min(self.grid_height - 1, self.player_pos[1] + 1)\n",
    "            reward = -np.sqrt((self.player_pos[0]-self.target_pos[0])**2 + (self.player_pos[1]-self.target_pos[1])**2)\n",
    "        elif action == 2:  # left\n",
    "            self.player_pos[0] = max(0, self.player_pos[0] - 1)\n",
    "            reward = -np.sqrt((self.player_pos[0]-self.target_pos[0])**2 + (self.player_pos[1]-self.target_pos[1])**2)\n",
    "        elif action == 3:  # right\n",
    "            self.player_pos[0] = min(self.grid_width - 1, self.player_pos[0] + 1)\n",
    "            reward = -np.sqrt((self.player_pos[0]-self.target_pos[0])**2 + (self.player_pos[1]-self.target_pos[1])**2)\n",
    "        \n",
    "        if self.player_pos == self.target_pos:\n",
    "            reward += 2000\n",
    "            done = True\n",
    "        elif self.player_pos == self.obstacle1_pos:\n",
    "            reward -= 1000\n",
    "            done = True\n",
    "\n",
    "    \n",
    "        else:\n",
    "            reward -= 1\n",
    "            done = False\n",
    "        state1 = np.array([self.player_pos[0],self.player_pos[1],self.obstacle1_pos[0],self.obstacle1_pos[1]])\n",
    "        return state1, reward, done, {}\n",
    "    \n",
    "    def reset(self):\n",
    "        self.player_pos = [0, 0]\n",
    "        self.obstacle1_pos = [np.random.randint(low = 3,high=16,size=None),np.random.randint(low = 3,high=12,size=None)]\n",
    "        self.obstacle1_image = pygame.Rect(self.obstacle1_pos[0]*self.grid_size,self.obstacle1_pos[1]*self.grid_size,self.grid_size,self.grid_size)\n",
    "        state1 = np.array([self.player_pos[0],self.player_pos[1],self.obstacle1_pos[0],self.obstacle1_pos[1]])\n",
    "        return state1\n",
    "\n",
    "    def render(self,score,i,num_episodes,mode = \"rgb_array\"):\n",
    "        self.screen.fill((255, 255, 255))\n",
    "        self.screen.blit(self.player_image, (self.player_pos[0] * self.grid_size, self.player_pos[1] * self.grid_size))\n",
    "        pygame.draw.rect(self.screen,(0,255,0),self.target_image)\n",
    "        pygame.draw.rect(self.screen,(255,0,0),self.obstacle1_image)\n",
    "        font = pygame.font.Font(None, 36)\n",
    "        score_text = font.render(f'Score: {score}', True, (0, 0, 255))\n",
    "        self.screen.blit(score_text, (600, 20))\n",
    "        # Save the frame as a PNG image\n",
    "        pygame.image.save(self.screen, 'frame.png')\n",
    "    \n",
    "        # Add the frame to the video\n",
    "        self.frame = cv2.imread('frame.png')\n",
    "        self.out.write(self.frame)\n",
    "        \n",
    "        pygame.display.update()\n",
    "        self.clock.tick(self.fps)\n",
    "        if i==num_episodes-1:\n",
    "             self.out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66aef283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Score: 1680.266396766882\n",
      "Score: 1659.2951965536179\n",
      "Score: 1724.4217422082152\n",
      "Score: 1705.854547561415\n",
      "Score: 1712.7633934418836\n",
      "Score: 1720.3203497977318\n",
      "Score: 1677.5609863750146\n",
      "Score: 1720.5029737894251\n",
      "Score: 1674.238072876586\n",
      "Score: 1704.6679544723759\n",
      "Avg Score = 1697.989161384315\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = AgentEnv()   # Create the environment\n",
    "# model = PPO('MlpPolicy', env, verbose=1)  # Create the PPO agent\n",
    "# model.learn(total_timesteps=100000)    # Train the agent for 10000 timesteps\n",
    "# model.save('Documents\\Trained Model_2D\\Agent_Target_change_Obstacle_100000_timesteps')\n",
    "model = PPO.load('Documents\\Trained Model_2D\\Agent_Target_change_Obstacle_100000_timesteps.zip', env = env)\n",
    "\n",
    "                  \n",
    "obs = env.reset()\n",
    "score_tot = 0\n",
    "num_episodes = 10\n",
    "for i in range(num_episodes):\n",
    "    score = 0\n",
    "    while True:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, done,info = env.step(action)       \n",
    "        score += rewards\n",
    "        env.render(score,i,num_episodes)\n",
    "        if done == True:\n",
    "            break\n",
    "    print('Score: ' + str(score))\n",
    "    obs = env.reset()\n",
    "    score_tot += score\n",
    "print('Avg Score = ' + str(score_tot/num_episodes))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fae704f",
   "metadata": {},
   "source": [
    "## Randomized both Obstacle and Target Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc35925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.0 (SDL 2.0.16, Python 3.9.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import pygame\n",
    "import numpy as np\n",
    "import cv2\n",
    "class AgentEnv(gym.Env):\n",
    "    def __init__(self):        \n",
    "        pygame.init()\n",
    "        pygame.font.init()\n",
    "        self.width = 800\n",
    "        self.height = 600\n",
    "        self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.fps = 15   # frame per second\n",
    "        self.grid_size = 40\n",
    "         # Create a VideoWriter object to save the video\n",
    "        self.fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        self.out = cv2.VideoWriter('randomized_obstacle_and_target.mp4', self.fourcc, self.fps, (self.width, self.height))\n",
    "        \n",
    "        self.grid_width = self.width//self.grid_size ## no. of grids in row\n",
    "        self.grid_height = self.height//self.grid_size  ## no. of grids in column\n",
    "        \n",
    "        self.action_space = gym.spaces.Discrete(4)\n",
    "        ## self.observation_space = gym.spaces.Tuple((gym.spaces.Discrete(self.grid_width),gym.spaces.Discrete(self.grid_height)))\n",
    "        self.observation_space = gym.spaces.Box(np.array([0,0,0,0]),np.array([self.grid_width-1,self.grid_height-1,self.grid_width-1,self.grid_height-1]))\n",
    "        \n",
    "        self.agent_image = pygame.image.load('Documents\\TANK.png')\n",
    "        self.agent_image = pygame.transform.scale(self.agent_image,(self.grid_size ,self.grid_size))\n",
    "        self.player_image = pygame.transform.rotate(self.agent_image, 180)\n",
    "        self.player_pos = [0, 0]\n",
    "        self.target_pos = [self.grid_width - 7, self.grid_height - 1]\n",
    "        self.target_image = pygame.Rect(self.target_pos[0]*self.grid_size,self.target_pos[1]*self.grid_size,self.grid_size,self.grid_size)\n",
    "        \n",
    "        self.obstacle1_pos = [self.grid_width - 7, self.grid_height - 9]\n",
    "        self.obstacle1_image = pygame.Rect(self.obstacle1_pos[0]*self.grid_size,self.obstacle1_pos[1]*self.grid_size,self.grid_size,self.grid_size)\n",
    "\n",
    "    def step(self,action):\n",
    "        reward = 0\n",
    "        if action == 0:  # up\n",
    "            self.player_pos[1] = max(0, self.player_pos[1] - 1)\n",
    "            reward = -np.sqrt((self.player_pos[0]-self.target_pos[0])**2 + (self.player_pos[1]-self.target_pos[1])**2)\n",
    "        elif action == 1:  # down\n",
    "            self.player_pos[1] = min(self.grid_height - 1, self.player_pos[1] + 1)\n",
    "            reward = -np.sqrt((self.player_pos[0]-self.target_pos[0])**2 + (self.player_pos[1]-self.target_pos[1])**2)\n",
    "        elif action == 2:  # left\n",
    "            self.player_pos[0] = max(0, self.player_pos[0] - 1)\n",
    "            reward = -np.sqrt((self.player_pos[0]-self.target_pos[0])**2 + (self.player_pos[1]-self.target_pos[1])**2)\n",
    "        elif action == 3:  # right\n",
    "            self.player_pos[0] = min(self.grid_width - 1, self.player_pos[0] + 1)\n",
    "            reward = -np.sqrt((self.player_pos[0]-self.target_pos[0])**2 + (self.player_pos[1]-self.target_pos[1])**2)\n",
    "        \n",
    "        if self.player_pos == self.target_pos:\n",
    "            reward += 2000\n",
    "            done = True\n",
    "        elif self.player_pos == self.obstacle1_pos:\n",
    "            reward -= 1000\n",
    "            done = True\n",
    "\n",
    "    \n",
    "        else:\n",
    "            reward -= 1\n",
    "            done = False\n",
    "        state1 = np.array([self.player_pos[0],self.player_pos[1],self.obstacle1_pos[0],self.obstacle1_pos[1]])\n",
    "        return state1, reward, done, {}\n",
    "    \n",
    "    def reset(self):\n",
    "        self.player_pos = [0, 0]\n",
    "        self.obstacle1_pos = [np.random.randint(low = 3,high=19,size=None),np.random.randint(low = 3,high=14,size=None)]\n",
    "        self.obstacle1_image = pygame.Rect(self.obstacle1_pos[0]*self.grid_size,self.obstacle1_pos[1]*self.grid_size,self.grid_size,self.grid_size)\n",
    "        self.target_pos = [np.random.randint(low = 3,high=19,size=None),np.random.randint(low = 13,high=14,size=None)]\n",
    "        self.target_image = pygame.Rect(self.target_pos[0]*self.grid_size,self.target_pos[1]*self.grid_size,self.grid_size,self.grid_size)\n",
    "        state1 = np.array([self.player_pos[0],self.player_pos[1],self.obstacle1_pos[0],self.obstacle1_pos[1]])\n",
    "        return state1\n",
    "\n",
    "    def render(self,score,i,num_episodes,mode = \"rgb_array\"):\n",
    "        self.screen.fill((255, 255, 255))\n",
    "        self.screen.blit(self.player_image, (self.player_pos[0] * self.grid_size, self.player_pos[1] * self.grid_size))\n",
    "        pygame.draw.rect(self.screen,(0,255,0),self.target_image)\n",
    "        pygame.draw.rect(self.screen,(255,0,0),self.obstacle1_image)\n",
    "        font = pygame.font.Font(None, 36)\n",
    "        score_text = font.render(f'Score: {score}', True, (0, 0, 255))\n",
    "        self.screen.blit(score_text, (600, 20))\n",
    "         # Save the frame as a PNG image\n",
    "        pygame.image.save(self.screen, 'frame.png')\n",
    "    \n",
    "        # Add the frame to the video\n",
    "        self.frame = cv2.imread('frame.png')\n",
    "        self.out.write(self.frame)\n",
    "        \n",
    "        pygame.display.update()\n",
    "        self.clock.tick(self.fps)\n",
    "        if i==num_episodes-1:\n",
    "             self.out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c275a8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\gym\\spaces\\box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Score: 1147.6649607755871\n",
      "Score: -259.92833832087854\n",
      "Score: -3867.385031306523\n",
      "Avg Score = -993.2161362839382\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "env = AgentEnv()   # Create the environment\n",
    "# model = PPO('MlpPolicy', env, verbose=1)  # Create the PPO agent\n",
    "# model.learn(total_timesteps=100000)    # Train the agent for 10000 timesteps\n",
    "# model.save('Documents\\Trained Model_2D\\Agent_rand_Target_rand_Obstacle_100000_timesteps')\n",
    "model = PPO.load('Documents\\Trained Model_2D\\Agent_rand_Target_rand_Obstacle_100000_timesteps.zip', env = env)\n",
    "\n",
    "                  \n",
    "obs = env.reset()\n",
    "score_tot = 0\n",
    "num_episodes = 3\n",
    "for i in range(num_episodes):\n",
    "    score = 0\n",
    "    while True:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, done,info = env.step(action)       \n",
    "        score += rewards\n",
    "        env.render(score,i,num_episodes)\n",
    "        if done == True:\n",
    "            break\n",
    "    print('Score: ' + str(score))\n",
    "    obs = env.reset()\n",
    "    score_tot += score\n",
    "print('Avg Score = ' + str(score_tot/num_episodes))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f4a258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ab887e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
